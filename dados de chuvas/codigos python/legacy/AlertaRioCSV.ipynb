{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "790863e4-6283-4c9e-85d8-c177ba886dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Arrays\n",
    "import pandas as pd # Tratamento de dados tabulares (planilhas)\n",
    "import os # Gerenciamento de arquivos e pastas\n",
    "from datetime import datetime, timedelta # Tratamento de datas e horas\n",
    "import re # Buscar padrões de texto\n",
    "import shutil # Deletar pastas\n",
    "from warnings import filterwarnings # Silenciar mensagens irritantes :)\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27704086-1de9-4cc1-ae96-80c6775314e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Código refeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0657c465-ea86-4f2b-a692-bf6e3bb5d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apaga_titulo_txt(arquivo, n_linhas = 4):\n",
    "    '''Recebe um arquivo txt. Apaga até a nésima linha do arquivo (por padrão até a 4ª).\n",
    "        Serve para apagar o titulo dos arquivos (Relatório  pluviométrico...)'''\n",
    "    with open(arquivo,\"r\") as file:\n",
    "        linhas = file.readlines()\n",
    "        indice_linha = 1\n",
    "        if 'RelatÃ³rio' in linhas[0]:\n",
    "            with open(arquivo,\"w\") as file:\n",
    "                for linha in linhas:\n",
    "                    if indice_linha > n_linhas:\n",
    "                        file.write(linha)\n",
    "                    indice_linha += 1\n",
    "    file.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ae4a341e-50b3-46f2-9ff1-b0c1eb36e711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def txt_para_csv(entrada, pasta_save = None):\n",
    "    '''Converte os arquivos txt para o formato csv\n",
    "        entrada: string com diretorio da pasta txt criada por DownloadAlertaRio\n",
    "        pasta_save: None|string com diretorio a ser criado (ou existente) onde os\n",
    "        arquivos csv serão salvos    \n",
    "    '''\n",
    "    \n",
    "    if pasta_save == None:\n",
    "        diretorio = os.path.dirname(entrada)\n",
    "        pasta_save = os.path.join(diretorio, 'csv')\n",
    "        \n",
    "    if not os.path.exists(pasta_save):\n",
    "        os.makedirs(pasta_save)\n",
    "\n",
    "    # Caminho do arquivo de saída\n",
    "    nome_csv = os.path.basename(entrada).replace('.txt', '.csv')\n",
    "    saida_csv = os.path.join(pasta_save, nome_csv)\n",
    "    \n",
    "    # Abrir o arquivo de entrada e criar o arquivo de saída\n",
    "    with open(entrada, 'r', encoding='utf-8') as txt, open(saida_csv, 'w', encoding='utf-8') as csv:\n",
    "        for n_linha, linha in enumerate(txt, start = 1):\n",
    "            # Corrigindo possíveis inconsistencias com as colunas que terminam com 'min' ou 'h'\n",
    "\n",
    "            # Elementos presentes na linha (\"palavras\")\n",
    "            valores = linha.split()\n",
    "            n_elementos = len(valores)\n",
    "            \n",
    "            if n_linha == 1: # primeira linha (nome das colunas)\n",
    "                # Lista para armazenar os nomes das colunas corrigidas\n",
    "                colunas_corrigidas = []\n",
    "                # indice de um elemento\n",
    "                i = 0\n",
    "                while i < n_elementos:\n",
    "                    # Verificando se a palavra é seguida de outra palavra como 'min' ou 'h'\n",
    "                    # para juntá-las em uma unica string\n",
    "                    if i + 1 < n_elementos and (valores[i + 1] == 'min' or valores[i + 1] == 'h'):\n",
    "                        # Junta as duas strings acrescentando ',' no final\n",
    "                        colunas_corrigidas.append(f\"{valores[i]} {valores[i + 1]},\")\n",
    "                        i += 2  # Pula o próximo elemento (ignorando a próxima palavra que deve ser 'min' ou 'h')\n",
    "                    else:\n",
    "                        # Se a strng não é seguida de outra string 'min' ou 'h'\n",
    "                        # apenas é adicionado ',' no final\n",
    "                        colunas_corrigidas.append(valores[i]+',')\n",
    "                        i += 1\n",
    "                # Atualizando os nomes das colunas na primeira linha pelos novos valores corrigidos  \n",
    "                valores = colunas_corrigidas\n",
    "                \n",
    "            else:\n",
    "                # Caso a coluna HBV esteja vazia, adiciona um valor 'nan'\n",
    "                # A coluna HBV sempre é a 3ª (indice 2)\n",
    "                if valores[2] != 'HBV':\n",
    "                    valores.insert(2,'nan')\n",
    "\n",
    "                # Substituindo todos os 'ND' por nan\n",
    "                valores = ['nan' if elemento == 'ND' else elemento for elemento in valores]\n",
    "                \n",
    "                # Percorrendo os dados presentes na linha para adicionar ','\n",
    "                # no ultimo indice\n",
    "                valores = [elemento+',' for elemento in valores]\n",
    "\n",
    "            # Colocando '\\n' no ultimo elemento indicando o fim da linha\n",
    "            valores[-1] = valores[-1].replace(',', '\\n')\n",
    "                \n",
    "            linha_csv = ''.join(valores)\n",
    "            csv.write(linha_csv + '\\n')\n",
    "    \n",
    "    print(f\"Arquivo convertido para CSV em: {saida_csv}\", end = '\\r')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "89592b62-5ef3-41dc-896e-82049ebad7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_dados_faltantes(dataframe):\n",
    "    '''Converte colunas do DataFrame dos CSVs, depois da coluna 'HBV', para o tipo numérico \n",
    "        e preenche os valores faltantes pela mediana das colunas\n",
    "\n",
    "        Parâmetros:\n",
    "            dataframe: pd.DataFrame\n",
    "        Retorna DataFrame (DataFrame tratado)\n",
    "    '''\n",
    "    \n",
    "    # Retirando dados faltantes substituindo pela mediana da coluna\n",
    "    colunas_converter = dataframe.iloc[:,3:].columns.to_list() # colunas depois da 'HBV'\n",
    "    dataframe[colunas_converter] = dataframe[colunas_converter].apply(pd.to_numeric)\n",
    "    dataframe[colunas_converter] = dataframe[colunas_converter].apply(lambda x: x.fillna(x.median()))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d8bdb90c-2f1f-442e-bf7c-19c491cfe783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrigir_hbv(dataframe):\n",
    "    '''Corrige as colunas de Dia e Hora cancelando os efeitos do Horário Brasileiro de Verão (HBV)\n",
    "        \n",
    "        Parâmetros:\n",
    "           dataframe: pd.DataFrame\n",
    "        Retorna DataFrame (DataFrame tratado)\n",
    "    '''\n",
    "    \n",
    "    # Data Frame com as colunas que possuem horario de verão \n",
    "    dados_HBV = dataframe.loc[dataframe.HBV == 'HBV', ['Dia', 'Hora']].copy()\n",
    "    \n",
    "    if dados_HBV.empty == False: # Verifica se existe datas com horario de verão no dataframe\n",
    "        # Cria uma coluna unindo a informação de data e hora no formato datetime\n",
    "        dados_HBV['data_hora'] = pd.to_datetime(dados_HBV['Dia'] + ' ' + dados_HBV['Hora'], format = '%d/%m/%Y  %H:%M:%S')\n",
    "        \n",
    "        # Variável para retirar 1 hora dos dados\n",
    "        correcao_hbv = timedelta(hours = 1)\n",
    "        \n",
    "        # Corrigindo o horário\n",
    "        dados_HBV['data_hora'] = dados_HBV['data_hora'] - correcao_hbv\n",
    "        \n",
    "        # Atualizando as colunas Dia e Hora do dataframe dados_HBV\n",
    "        dados_HBV['Dia'] = dados_HBV['data_hora'].apply(lambda x: x.strftime('%d/%m/%Y'))\n",
    "        dados_HBV['Hora'] = dados_HBV['data_hora'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "        \n",
    "        # Atribuindo ao dataframe original os valores alterados de Dia e Hora corrigidos\n",
    "        dataframe.loc[dataframe.HBV == 'HBV', ['Dia', 'Hora']] = dados_HBV[['Dia', 'Hora']]\n",
    "    \n",
    "    # Elimina a coluna HBV\n",
    "    dataframe.drop(columns = 'HBV', inplace = True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5158ad2-9fc8-4738-b00d-b49730d6d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_estacoes(pasta_csv,pasta_save):\n",
    "    ''' Cria um DataFrame único com todas as datas para cada uma das estações\n",
    "         \n",
    "        Parâmetros:\n",
    "           dataframe: pd.DataFrame\n",
    "        Retorna DataFrame (DataFrame tratado)\n",
    "    '''\n",
    "    \n",
    "    # Criando pasta_csv para salvar os arquivos (caso não exista)\n",
    "    if os.path.exists(pasta_save) == False:\n",
    "        os.makedirs(pasta_save)\n",
    "    \n",
    "    # Lista com os nomes dos arquivos txt presentes no diretorio\n",
    "    arquivos = [csv for csv in os.listdir(pasta_csv) if '.csv' in csv]\n",
    "    \n",
    "    # Expressão para encontrar o padrão de texto representando o ano e mes do arquivo\n",
    "    # 6 digitos (ex: 202401)\n",
    "    padrao_arquivo = re.compile(r'_(\\d{6})_Plv\\.csv')\n",
    "    \n",
    "    # Separar os arquivos pela estacao, usando o trecho com a data e _Plv como separador\n",
    "    # (Porque o nome da estação vem antes deste trecho!)\n",
    "    # Ex: anchieta_199701_Plv -> (utilizando o trecho como separador) ['anchieta'] \n",
    "    estacoes = np.array([re.split(padrao_arquivo, csv)[0] for csv in arquivos])\n",
    "    estacoes = np.unique(estacoes) #Tirando estaçoes repetidas\n",
    "\n",
    "    # Criando progresso de loading\n",
    "    loading = 0\n",
    "    # estacoes\n",
    "    for estacao in estacoes:\n",
    "        # Criando um buscador de estacoes pelo nome\n",
    "        padrao_estacao = re.compile(f'{estacao}')\n",
    "        # Lista com os arquivos referentes a mesma estação\n",
    "        arquivos_estacao = [os.path.join(pasta_csv, arquivo) for arquivo in arquivos if padrao_estacao.match(arquivo)]\n",
    "        print(f'Separando arquivos por estacoes...', end = '\\r')\n",
    "    \n",
    "        # Lista de dataframes\n",
    "        df_estacao = []\n",
    "\n",
    "        # Progresso de Loading para o tratamento e junção dos arquivos\n",
    "        for arquivo in arquivos_estacao:\n",
    "            # Abrindo arquivo pulando descrição em texto nas 3 primeiras linhas do arquivo\n",
    "            dataframe = pd.read_csv(arquivo)\n",
    "            # Tratando arquivos\n",
    "            dataframe = tratar_dados_faltantes(dataframe)\n",
    "            # Corrigindo horario de verão\n",
    "            dataframe = corrigir_hbv(dataframe)\n",
    "            # Adiciona o dataframe corrigido na lista df_estacao (Como se fosse um salvamento)\n",
    "            df_estacao.append(dataframe)\n",
    "        \n",
    "        # Juntando todos os dataframes em um só!\n",
    "        df_estacao = pd.concat(df_estacao)\n",
    "        # index = False para não criar uma coluna extra com o índice\n",
    "        df_estacao.to_csv(os.path.join(pasta_save, estacao + '.csv'), index = False)\n",
    "        # Progresso do loading geral\n",
    "        print(f'Tratando e juntando dataframes : {loading*100/len(estacoes):.2f}', end = '\\r')\n",
    "        loading += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee5481-cbd1-4349-9219-ea1c4bdd03fd",
   "metadata": {},
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fedbfe08-3a90-48ca-8e27-4d5b03d4b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de conteúdo retornado: application/zip\n",
      "Arquivo baixado com sucesso em: C:\\Users\\Edu16\\Documents\\ic\\codigos python\\teste\\dados_brutos\\zip\\DadosPluviometricos1997.zip\n",
      "Tipo de conteúdo retornado: application/zip\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Edu16\\\\Documents\\\\ic\\\\codigos python\\\\teste\\\\dados_brutos\\\\zip\\\\DadosPluviometricos1998.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dir_padrao \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEdu16\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mic\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcodigos python\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mteste\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Download dos dados e criação de pastas\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mAlertaRioCSV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_alertario\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_padrao\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Pasta onde estão baixados os arquivos txt do alerta rio\u001b[39;00m\n\u001b[0;32m      8\u001b[0m pasta_txt \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_padrao,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdados_brutos/txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\ic\\codigos python\\teste\\AlertaRioCSV.py:68\u001b[0m, in \u001b[0;36mdownload_alertario\u001b[1;34m(dir_padrao)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Salva o conteúdo da resposta como um arquivo se for um ZIP\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/zip\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m content_type:\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     69\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(response\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArquivo baixado com sucesso em: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Edu16\\\\Documents\\\\ic\\\\codigos python\\\\teste\\\\dados_brutos\\\\zip\\\\DadosPluviometricos1998.zip'"
     ]
    }
   ],
   "source": [
    "from teste import AlertaRioCSV\n",
    "\n",
    "dir_padrao = r\"C:\\Users\\Edu16\\Documents\\ic\\codigos python\\teste\"\n",
    "# Download dos dados e criação de pastas\n",
    "AlertaRioCSV.download_alertario(dir_padrao)\n",
    "\n",
    "# Pasta onde estão baixados os arquivos txt do alerta rio\n",
    "pasta_txt = os.path.join(dir_padrao,\"dados_brutos/txt\")\n",
    "\n",
    "# Lista com os arquivos txt\n",
    "txts = [os.path.join(pasta_txt, txt) for txt in os.listdir(pasta_txt) \n",
    "       if '.txt' in txt]\n",
    "\n",
    "# Pasta CSV\n",
    "pasta_csv = os.path.join(dir_padrao, 'dados_brutos/csv')\n",
    "\n",
    "for txt in txts:\n",
    "    # Apagando a descricao dos txts\n",
    "    AlertaRioCSV.apaga_desc_txt(txt)\n",
    "    # Converte os arquivos txt para csv ajustando as colunas\n",
    "    AlertaRioCSV.txt_para_csv(txt, pasta_csv)\n",
    "\n",
    "# Remove a pasta txts após a conversão para csv\n",
    "shutil.rmtree(pasta_txt)\n",
    "\n",
    "# Pasta onde serão salvos as tabelas concantenadas por estação\n",
    "pasta_save = os.path.join(dir_padrao,'alerta_rio_csv')\n",
    "# Criando tabelas concantendadas por estação\n",
    "AlertaRioCSV.csv_estacoes(pasta_csv, pasta_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19c5d3d2-a061-45c7-af55-e9c7849ef793",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'c:/users/edu16/Documents/ic/codigos python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc:/users/edu16/Documents/ic/codigos python\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      2\u001b[0m     file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CienciaDeDados\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'c:/users/edu16/Documents/ic/codigos python'"
     ]
    }
   ],
   "source": [
    "with open('c:/users/edu16/Documents/ic/codigos python') as file:\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3372635d-ddb7-4de8-b0dc-d4ffc24c8387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasta zip?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir_padrao = r\"C:\\Users\\Edu16\\Documents\\ic\\codigos python\\teste\"\n",
    "\n",
    "dados_brutos = os.path.join(dir_padrao,'dados_brutos')\n",
    "pasta_zip = os.path.join(dados_brutos,'zip')\n",
    "pasta_txt = os.path.join(dados_brutos,'txt')\n",
    "\n",
    "if os.path.exists(dados_brutos) == False:\n",
    "    os.makedirs(dados_brutos)\n",
    "\n",
    "if os.path.exists(pasta_zip) == False:\n",
    "    os.makedirs(pasta_zip)\n",
    "    print('pasta zip?')\n",
    "\n",
    "if os.path.exists(pasta_txt) == False:\n",
    "    os.makedirs(pasta_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CienciaDeDados] *",
   "language": "python",
   "name": "conda-env-CienciaDeDados-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
