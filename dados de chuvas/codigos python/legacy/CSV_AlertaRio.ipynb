{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790863e4-6283-4c9e-85d8-c177ba886dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Arrays\n",
    "import pandas as pd # Tratamento de dados tabulares (planilhas)\n",
    "import os # Gerenciamento de arquivos e pastas\n",
    "from datetime import datetime, timedelta # Tratamento de datas e horas\n",
    "import re # Buscar padrões de texto\n",
    "import shutil # Deletar pastas\n",
    "from warnings import filterwarnings # Silenciar mensagens irritantes :)\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27704086-1de9-4cc1-ae96-80c6775314e6",
   "metadata": {},
   "source": [
    "# Código refeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "0657c465-ea86-4f2b-a692-bf6e3bb5d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apaga_titulo_txt(arquivo, n_linhas = 4):\n",
    "    '''Recebe um arquivo txt. Apaga até a nésima linha do arquivo (por padrão até a 4ª).\n",
    "        Serve para apagar o titulo dos arquivos (Relatório  pluviométrico...)'''\n",
    "    with open(arquivo,\"r\") as file:\n",
    "        linhas = file.readlines()\n",
    "        indice_linha = 1\n",
    "        if 'RelatÃ³rio' in linhas[0]:\n",
    "            with open(arquivo,\"w\") as file:\n",
    "                for linha in linhas:\n",
    "                    if indice_linha > n_linhas:\n",
    "                        file.write(linha)\n",
    "                    indice_linha += 1\n",
    "    file.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ae4a341e-50b3-46f2-9ff1-b0c1eb36e711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def txt_para_csv(entrada, pasta_save = None):\n",
    "    '''Converte os arquivos txt para o formato csv\n",
    "        entrada: string com diretorio da pasta txt criada por DownloadAlertaRio\n",
    "        pasta_save: None|string com diretorio a ser criado (ou existente) onde os\n",
    "        arquivos csv serão salvos    \n",
    "    '''\n",
    "    \n",
    "    if pasta_save == None:\n",
    "        diretorio = os.path.dirname(entrada)\n",
    "        pasta_save = os.path.join(diretorio, 'csv')\n",
    "        \n",
    "    if not os.path.exists(pasta_save):\n",
    "        os.makedirs(pasta_save)\n",
    "\n",
    "    # Caminho do arquivo de saída\n",
    "    nome_csv = os.path.basename(entrada).replace('.txt', '.csv')\n",
    "    saida_csv = os.path.join(pasta_save, nome_csv)\n",
    "    \n",
    "    # Abrir o arquivo de entrada e criar o arquivo de saída\n",
    "    with open(entrada, 'r', encoding='utf-8') as txt, open(saida_csv, 'w', encoding='utf-8') as csv:\n",
    "        for n_linha, linha in enumerate(txt, start = 1):\n",
    "            # Corrigindo possíveis inconsistencias com as colunas que terminam com 'min' ou 'h'\n",
    "\n",
    "            # Elementos presentes na linha (\"palavras\")\n",
    "            valores = linha.split()\n",
    "            n_elementos = len(valores)\n",
    "            \n",
    "            if n_linha == 1: # primeira linha (nome das colunas)\n",
    "                # Lista para armazenar os nomes das colunas corrigidas\n",
    "                colunas_corrigidas = []\n",
    "                # indice de um elemento\n",
    "                i = 0\n",
    "                while i < n_elementos:\n",
    "                    # Verificando se a palavra é seguida de outra palavra como 'min' ou 'h'\n",
    "                    # para juntá-las em uma unica string\n",
    "                    if i + 1 < n_elementos and (valores[i + 1] == 'min' or valores[i + 1] == 'h'):\n",
    "                        # Junta as duas strings acrescentando ',' no final\n",
    "                        colunas_corrigidas.append(f\"{valores[i]} {valores[i + 1]},\")\n",
    "                        i += 2  # Pula o próximo elemento (ignorando a próxima palavra que deve ser 'min' ou 'h')\n",
    "                    else:\n",
    "                        # Se a strng não é seguida de outra string 'min' ou 'h'\n",
    "                        # apenas é adicionado ',' no final\n",
    "                        colunas_corrigidas.append(valores[i]+',')\n",
    "                        i += 1\n",
    "                # Atualizando os nomes das colunas na primeira linha pelos novos valores corrigidos  \n",
    "                valores = colunas_corrigidas\n",
    "                \n",
    "            else:\n",
    "                # Caso a coluna HBV esteja vazia, adiciona um valor 'nan'\n",
    "                # A coluna HBV sempre é a 3ª (indice 2)\n",
    "                if valores[2] != 'HBV':\n",
    "                    valores.insert(2,'nan')\n",
    "\n",
    "                # Substituindo todos os 'ND' por nan\n",
    "                valores = ['nan' if elemento == 'ND' else elemento for elemento in valores]\n",
    "                \n",
    "                # Percorrendo os dados presentes na linha para adicionar ','\n",
    "                # no ultimo indice\n",
    "                valores = [elemento+',' for elemento in valores]\n",
    "\n",
    "            # Colocando '\\n' no ultimo elemento indicando o fim da linha\n",
    "            valores[-1] = valores[-1].replace(',', '\\n')\n",
    "                \n",
    "            linha_csv = ''.join(valores)\n",
    "            csv.write(linha_csv + '\\n')\n",
    "    \n",
    "    print(f\"Arquivo convertido para CSV em: {saida_csv}\", end = '\\r')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "89592b62-5ef3-41dc-896e-82049ebad7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_dados_faltantes(dataframe):\n",
    "    '''Converte colunas do DataFrame dos CSVs, depois da coluna 'HBV', para o tipo numérico \n",
    "        e preenche os valores faltantes pela mediana das colunas\n",
    "\n",
    "        Parâmetros:\n",
    "            dataframe: pd.DataFrame\n",
    "        Retorna DataFrame (DataFrame tratado)\n",
    "    '''\n",
    "    \n",
    "    # Retirando dados faltantes substituindo pela mediana da coluna\n",
    "    colunas_converter = dataframe.iloc[:,3:].columns.to_list() # colunas depois da 'HBV'\n",
    "    dataframe[colunas_converter] = dataframe[colunas_converter].apply(pd.to_numeric)\n",
    "    dataframe[colunas_converter] = dataframe[colunas_converter].apply(lambda x: x.fillna(x.median()))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d8bdb90c-2f1f-442e-bf7c-19c491cfe783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrigir_hbv(dataframe):\n",
    "    '''Corrige as colunas de Dia e Hora cancelando os efeitos do Horário Brasileiro de Verão (HBV)\n",
    "        \n",
    "        Parâmetros:\n",
    "           dataframe: pd.DataFrame\n",
    "        Retorna DataFrame (DataFrame tratado)\n",
    "    '''\n",
    "    \n",
    "    # Data Frame com as colunas que possuem horario de verão \n",
    "    dados_HBV = dataframe.loc[dataframe.HBV == 'HBV', ['Dia', 'Hora']].copy()\n",
    "    \n",
    "    if dados_HBV.empty == False: # Verifica se existe datas com horario de verão no dataframe\n",
    "        # Cria uma coluna unindo a informação de data e hora no formato datetime\n",
    "        dados_HBV['data_hora'] = pd.to_datetime(dados_HBV['Dia'] + ' ' + dados_HBV['Hora'], format = '%d/%m/%Y  %H:%M:%S')\n",
    "        \n",
    "        # Variável para retirar 1 hora dos dados\n",
    "        correcao_hbv = timedelta(hours = 1)\n",
    "        \n",
    "        # Corrigindo o horário\n",
    "        dados_HBV['data_hora'] = dados_HBV['data_hora'] - correcao_hbv\n",
    "        \n",
    "        # Atualizando as colunas Dia e Hora do dataframe dados_HBV\n",
    "        dados_HBV['Dia'] = dados_HBV['data_hora'].apply(lambda x: x.strftime('%d/%m/%Y'))\n",
    "        dados_HBV['Hora'] = dados_HBV['data_hora'].apply(lambda x: x.strftime('%H:%M:%S'))\n",
    "        \n",
    "        # Atribuindo ao dataframe original os valores alterados de Dia e Hora corrigidos\n",
    "        dataframe.loc[dataframe.HBV == 'HBV', ['Dia', 'Hora']] = dados_HBV[['Dia', 'Hora']]\n",
    "    \n",
    "    # Elimina a coluna HBV\n",
    "    dataframe.drop(columns = 'HBV', inplace = True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5158ad2-9fc8-4738-b00d-b49730d6d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_estacoes(pasta_csv,pasta_save):\n",
    "    ''' Cria um DataFrame único com todas as datas para cada uma das estações\n",
    "         \n",
    "        Parâmetros:\n",
    "           dataframe: pd.DataFrame\n",
    "        Retorna DataFrame (DataFrame tratado)\n",
    "    '''\n",
    "    \n",
    "    # Criando pasta_csv para salvar os arquivos (caso não exista)\n",
    "    if os.path.exists(pasta_save) == False:\n",
    "        os.makedirs(pasta_save)\n",
    "    \n",
    "    # Lista com os nomes dos arquivos txt presentes no diretorio\n",
    "    arquivos = [csv for csv in os.listdir(pasta_csv) if '.csv' in csv]\n",
    "    \n",
    "    # Expressão para encontrar o padrão de texto representando o ano e mes do arquivo\n",
    "    # 6 digitos (ex: 202401)\n",
    "    padrao_arquivo = re.compile(r'_(\\d{6})_Plv\\.csv')\n",
    "    \n",
    "    # Separar os arquivos pela estacao, usando o trecho com a data e _Plv como separador\n",
    "    # (Porque o nome da estação vem antes deste trecho!)\n",
    "    # Ex: anchieta_199701_Plv -> (utilizando o trecho como separador) ['anchieta'] \n",
    "    estacoes = np.array([re.split(padrao_arquivo, csv)[0] for csv in arquivos])\n",
    "    estacoes = np.unique(estacoes) #Tirando estaçoes repetidas\n",
    "\n",
    "    # Criando progresso de loading\n",
    "    loading = 0\n",
    "    # estacoes\n",
    "    for estacao in estacoes:\n",
    "        # Criando um buscador de estacoes pelo nome\n",
    "        padrao_estacao = re.compile(f'{estacao}')\n",
    "        # Lista com os arquivos referentes a mesma estação\n",
    "        arquivos_estacao = [os.path.join(pasta_csv, arquivo) for arquivo in arquivos if padrao_estacao.match(arquivo)]\n",
    "        print(f'Separando arquivos por estacoes...', end = '\\r')\n",
    "    \n",
    "        # Lista de dataframes\n",
    "        df_estacao = []\n",
    "\n",
    "        # Progresso de Loading para o tratamento e junção dos arquivos\n",
    "        for arquivo in arquivos_estacao:\n",
    "            # Abrindo arquivo pulando descrição em texto nas 3 primeiras linhas do arquivo\n",
    "            dataframe = pd.read_csv(arquivo)\n",
    "            # Tratando arquivos\n",
    "            dataframe = tratar_dados_faltantes(dataframe)\n",
    "            # Corrigindo horario de verão\n",
    "            dataframe = corrigir_hbv(dataframe)\n",
    "            # Adiciona o dataframe corrigido na lista df_estacao (Como se fosse um salvamento)\n",
    "            df_estacao.append(dataframe)\n",
    "        \n",
    "        # Juntando todos os dataframes em um só!\n",
    "        df_estacao = pd.concat(df_estacao)\n",
    "        # index = False para não criar uma coluna extra com o índice\n",
    "        df_estacao.to_csv(os.path.join(pasta_save, estacao + '.csv'), index = False)\n",
    "        # Progresso do loading geral\n",
    "        print(f'Tratando e juntando dataframes : {loading*100/len(estacoes):.2f}', end = '\\r')\n",
    "        loading += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fedbfe08-3a90-48ca-8e27-4d5b03d4b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo convertido para CSV em: c:/users/edu16/Documents/ic/codigos python/dados_brutos/csv\\vidigal_202412_Plv.csv.csvsvsvcsv\r"
     ]
    }
   ],
   "source": [
    "# Pasta onde estão baixados os arquivos txt do alerta rio\n",
    "pasta_txt = \"dados_brutos/txts\"\n",
    "\n",
    "txts = [os.path.join(pasta_txt, txt) for txt in os.listdir(pasta_txt) \n",
    "       if '.txt' in txt]\n",
    "\n",
    "for txt in txts:\n",
    "    apaga_titulo_txt(txt)\n",
    "    txt_para_csv(txt, 'c:/users/edu16/Documents/ic/codigos python/dados_brutos/csv')\n",
    "\n",
    "# Remove a pasta txts e zip após a conversão para csv\n",
    "shutil.rmtree(pasta_txt)\n",
    "shutil.rmtree(pasta_zip)\n",
    "\n",
    "\n",
    "# Pasta onde estão baixados os arquivos txt do alerta rio\n",
    "# Pasta onde serão salvos os arquivos de cada estação convertidos para csv  \n",
    "pasta_csv = 'c:/users/edu16/Documents/ic/codigos python/dados_brutos/csv'\n",
    "pasta_csv = 'c:/users/edu16/Documents/ic/codigos python/alerta_rio_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1eeaf29-5da1-4659-b9c5-2c4af6288026",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAlertaRioCSV\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m corrige_hbv\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from ..AlertaRioCSV import corrige_hbv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CienciaDeDados] *",
   "language": "python",
   "name": "conda-env-CienciaDeDados-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
